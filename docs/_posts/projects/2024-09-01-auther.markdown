---
layout: post
title: "Auther"
subtitle: "Person-to-person authentication app"
thumbnail: "/assets/heros/Auther.png"
tags: [project, design]
permalink: /auther/
startdate: "2024-06-01 00:00:00"
---
Auther is a codeword generation app for combatting identity cloning scams.
- When you're in person with people close to you, scan each other's QR codes to register each other on the Auther app.
- Then, when you chat remotely, tell each other the secret codewords generated by the Auther app.

At the moment, Auther is only available for Android. You can [get it now from GitHub](https://github.com/bgsulz/Auther/releases) (I recommend using [Obtanium.](https://obtainium.imranr.dev/)) It will arrive on open-source app stores (e.g. F-Droid) shortly, then Google Play, then the iOS App Store.

[Download from GitHub](https://github.com/bgsulz/Auther/releases){: .btn}

## Features

- TOTP-style codeword generation.
- QR code generation and scanning.
- "Emergency mode" (in case a registered person can't access their device, you can enter their secret passphrase instead of their codewords.)
- Edit, remove, and search through the app's list of registered people.

## Why does this app exist?

The age of zero-cost deepfakes is imminent. (See links below.) Some are already abusing this technology to run imposter scams. If you're reading this, you can probably sniff out a deepfake -- but can all your relatives and friends?

Using a single secret codeword may not be enough; if intercepted or guessed, your system is compromised. Auther perpetually updates your digital signature, enabling remote communication with confidence.

## How does it work?

Conceptually, it's not terribly complicated.
- When you start the app, you must set a secret passphrase. You'll use this to log into the app.
- Your secret passphrase is hashed and discarded.
- Your QR code sends the hash of your passphrase; scanning someone else's QR code adds their hash to a list.
- The codewords are derived from another hash: `hash(userHash + otherHash + currentTime)` where `currentTime` refreshes every 30 seconds.

## How did you make it?

Auther is built with Flutter.

## "Get real. These scams are a non-issue."

See links below. The best case scenario is that this whole project turns out to be useless. I'd be quite happy about that.

**1. Advances across several fields of AI have yielded likeness-cloning software of increasing ease.**
- [Early 2023 - "Microsoft’s new AI can simulate anyone’s voice with 3 seconds of audio."](https://arstechnica.com/information-technology/2023/01/microsofts-new-ai-can-simulate-anyones-voice-with-3-seconds-of-audio/)
- [Early 2024 - "Microsoft’s VASA-1 can deepfake a person with one photo and one audio track."](https://arstechnica.com/information-technology/2024/04/microsofts-vasa-1-can-deepfake-a-person-with-one-photo-and-one-audio-track/)
- [Early 2024 - Alibaba EMO: "Input a single reference image and the vocal audio ... our method can generate ... videos - with expressive facial expressions."](https://humanaigc.github.io/emote-portrait-alive/)
- [Mid-2024 - "Using one photo and free software, someone can impersonate your appearance in a video chat."](https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/)
- [Late 2024 - "... users only need to provide a static portrait image and a driving performance video ... [our model] brings the expressiveness of portrait animation to a whole new level."](https://byteaigc.github.io/X-Portrait2/)
- [Late 2024 - DeepBrain AI's FLOAT: "... aims to synthesize talking portrait videos using a single source portrait image and driving audio."](https://deepbrainai-research.github.io/float/)
- [Late 2024 - CAP4D: "...create realistic 4D avatars using any number of reference images. ... The avatar can be controlled ... and rendered in real time."](https://felixtaubner.github.io/cap4d/)
- [Late 2024 - INFP: "...dynamically synthesize verbal ... interactive agent videos ... practical in instant communication ... [such as] video conferencing."](https://grisoon.github.io/INFP/)
- [Early 2025 - AlignDiT: "generates accurate, synchronized, and natural-sounding speech from aligned multimodal inputs."](https://mm.kaist.ac.kr/projects/AlignDiT/)
- [Early 2025 - Minimax-Speech: supports "one-shot voice cloning with exceptionally high similarity to the reference voice."](https://arxiv.org/html/2505.07916v1)
- [Mid-2025 - Runway Act-Two: "[t]ransfers ... movement ... with realistic motion, speech, and expression."](https://help.runwayml.com/hc/en-us/articles/42311337895827-Creating-with-Act-Two)
- [Mid-2025 - Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://humanaigc.github.io/wan-animate/)
    - This is an open-source model with no safeguards.

**1A. "Safeguards" to protect against nonconsensual voice cloning can be easily bypassed.**
- [Early 2025 - "AI can steal your voice, and there's not much you can do about it."](https://www.nbcwashington.com/news/national-international/ai-voice-cloning-software-flimsy-guardrails-report-finds/3862697/?os=4040nue0o)

**2. Bad actors are using tools like these to conduct imposter scams.**
- [Early 2023 - "In 2022, $11 million was stolen through thousands of impostor phone scams."](https://arstechnica.com/tech-policy/2023/03/rising-scams-use-ai-to-mimic-voices-of-loved-ones-in-financial-distress/)
- [Early 2023 - "[Arizona mother] believes scammers cloned her daughter’s voice in a fake kidnapping."](https://www.cnn.com/2023/04/29/us/ai-scam-calls-kidnapping-cec/index.html)
- [Early 2023 - "They thought loved ones were calling for help. It was an AI scam."](https://archive.ph/25TCt)
- [Early 2024 - "Deepfake scammer walks off with $25 million in first-of-its-kind AI heist."](https://arstechnica.com/information-technology/2024/02/deepfake-scammer-walks-off-with-25-million-in-first-of-its-kind-ai-heist/)
- [Early 2024 - "School athletic director arrested for framing principal using AI voice synthesis"](https://arstechnica.com/information-technology/2024/04/alleged-ai-voice-imitation-leads-to-arrest-in-baltimore-school-racism-controversy/)
- [Early 2024 - "A Brooklyn couple got a call from relatives who were being held ransom. Their voices -- like many others these days -- had been cloned."](https://www.newyorker.com/science/annals-of-artificial-intelligence/the-terrifying-ai-scam-that-uses-your-loved-ones-voice)
- [Late 2024 - "Just over half (53%) of businesses in the U.S. and U.K. have been targets of a [deepfake imposter scam] with 43% falling victim ..."](https://www.cfodive.com/news/deepfake-scams-escalate-hitting-53-percent-of-businesses/725836/)
- [Late 2024 - "UN: Southeast Asian cyber-fraud industry ‘outpacing’ law enforcement with new tools"](https://therecord.media/southeast-asian-cyber-fraud-outpaces-crackdown-efforts-united-nations)
- [Late 2024 - "Deepfake lovers swindle victims out of $46 million in Hong Kong AI scam"](https://arstechnica.com/ai/2024/10/deepfake-lovers-swindle-victims-out-of-46m-in-hong-kong-ai-scam/)
- [Early 2025 - "[M]y AI-cloned voice was used by the far right. ... It was chilling to hear ‘my voice’ repeating lies."](https://www.theguardian.com/commentisfree/2025/jan/07/ai-clone-voice-far-right-fake-audio)
- [Early 2025 - "[N]early one million euros ($1.04 million) [were] wired ... by a leading businessman after ... an artificial intelligence scam ..."]("https://www.reuters.com/technology/artificial-intelligence/italian-police-freeze-cash-ai-voice-scam-that-targeted-business-leaders-2025-02-12/")

**3. Though codewords are a recommended line of defense, they are fragile.**
- [Mid-2023 - "Nicoletti suggested all family members should adopt a 'safe word' ..."](https://www.goodmorningamerica.com/living/story/cybersecurity-expert-protect-family-ai-scams-100292080)
- [Mid-2024 - "... a safe word can be especially helpful for young ones or elderly relatives who may be difficult to contact otherwise."](https://archive.ph/Vr9eA)
- [Mid-2024 - "Defend Yourself against AI Impostor Scams with a Safe Word"](https://www.scientificamerican.com/article/a-safe-word-can-protect-against-ai-impostor-scams/)
    - "[My partner] provided an imaginary situation in which hostage-takers could use the word without even knowing its secret meaning. We’re still working to find one that’s foolproof."
    - "[My family and I] agreed on a code word based on a funny family lore story ... Hopefully we’ll be able to remember it ..."
- [Late 2024 - "The FBI now recommends choosing a secret password to thwart AI voice clones from tricking people."]()