---
layout: post
title: "Auther"
subtitle: "Person-to-person authentication app"
thumbnail: "/assets/heros/Auther.png"
tags: [project, design]
permalink: /auther/
startdate: "2024-06-01 00:00:00"
---
Auther is a codeword generation app for combatting identity cloning scams.
- When you're in person with people close to you, scan each other's QR codes to register each other on the Auther app.
- Then, when you chat remotely, tell each other the secret codewords generated by the Auther app.

At the moment, Auther is only available for Android. You can [get it now from GitHub](https://github.com/bgsulz/Auther/releases) (I recommend using [Obtanium.](https://obtainium.imranr.dev/)) It will arrive on open-source app stores (e.g. F-Droid) shortly, then Google Play, then the iOS App Store.

[Download from GitHub](https://github.com/bgsulz/Auther/releases){: .btn}

## Features

- TOTP-style codeword generation.
- QR code generation and scanning.
- "Emergency mode" (in case a registered person can't access their device, you can enter their secret passphrase instead of their codewords.)
- Edit, remove, and search through the app's list of registered people.

## Why does this app exist?

The age of zero-cost deepfakes is imminent. (See links below.) Some are already abusing this technology to run imposter scams. If you're reading this, you can probably sniff out a deepfake -- but can all your relatives and friends?

Using a single secret codeword may not be enough; if intercepted or guessed, your system is compromised. Auther perpetually updates your digital signature, enabling remote communication with confidence.

## How does it work?

Conceptually, it's not terribly complicated.
- When you start the app, you must set a secret passphrase. You'll use this to log into the app.
- Your secret passphrase is hashed and discarded.
- Your QR code sends the hash of your passphrase; scanning someone else's QR code adds their hash to a list.
- The codewords are derived from another hash: `hash(userHash + otherHash + currentTime)` where `currentTime` refreshes every 30 seconds.

## How did you make it?

Auther is built with Flutter.

## Get real. These scams are a non-issue.

See links below. The best case scenario is that this whole project turns out to be useless. I'd be quite happy about that.

**1. Advances across several fields of AI have yielded likeness-cloning software of increasing ease.**
[Early 2023 - "Microsoft’s new AI can simulate anyone’s voice with 3 seconds of audio."](https://arstechnica.com/information-technology/2023/01/microsofts-new-ai-can-simulate-anyones-voice-with-3-seconds-of-audio/)
[Early 2024 - "Microsoft’s VASA-1 can deepfake a person with one photo and one audio track."](https://arstechnica.com/information-technology/2024/04/microsofts-vasa-1-can-deepfake-a-person-with-one-photo-and-one-audio-track/)
[Early 2024 - Alibaba EMO: "Input a single reference image and the vocal audio ... our method can generate ... videos with expressive facial expressions."](https://humanaigc.github.io/emote-portrait-alive/)
[Mid-2024 - "Using one photo and free software, someone can impersonate your appearance in a video chat."](https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/)

**2. Bad actors are using tools like these to conduct imposter scams.**
[Early 2023 - "[Arizona mother] believes scammers cloned her daughter’s voice in a fake kidnapping."](https://www.cnn.com/2023/04/29/us/ai-scam-calls-kidnapping-cec/index.html)
[Early 2024 - "Deepfake scammer walks off with $25 million in first-of-its-kind AI heist."](https://arstechnica.com/information-technology/2024/02/deepfake-scammer-walks-off-with-25-million-in-first-of-its-kind-ai-heist/)
[Early 2024 - "School athletic director arrested for framing principal using AI voice synthesis"](https://arstechnica.com/information-technology/2024/04/alleged-ai-voice-imitation-leads-to-arrest-in-baltimore-school-racism-controversy/)
[Late 2024 - "Just over half (53%) of businesses in the U.S. and U.K. have been targets of a [deepfake imposter scam] with 43% falling victim ..."](https://www.cfodive.com/news/deepfake-scams-escalate-hitting-53-percent-of-businesses/725836/)